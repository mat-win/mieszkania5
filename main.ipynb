{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2zZniOSYKAi"
      },
      "source": [
        "import io\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sns\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import copy\n",
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peYR6msUYKAs"
      },
      "source": [
        "train_headers = ['price', 'type_of_destination', 'rent', 'ownership', 'price_per_meter', 'url', 'number_of_rooms', 'empty1', 'meters', 'used', 'max_floor', 'type_of_building', 'empty2', 'empty3', 'description', 'floor', 'empty4', 'heating', 'windows_type', 'built_in_year', 'empty5', 'date', 'type_of_material', 'ad', 'empty6', 'additionals'] \n",
        "train_dataframe_from_file = pd.read_csv('./train/train.tsv', names = train_headers, sep='\\t')\n",
        "\n",
        "test_headers = ['type_of_destination', 'rent', 'ownership', 'price_per_meter', 'url', 'number_of_rooms', 'empty1', 'meters', 'used', 'max_floor', 'type_of_building', 'empty2', 'empty3', 'description', 'floor', 'empty4', 'heating', 'windows_type', 'built_in_year', 'empty5', 'date', 'type_of_material', 'ad', 'empty6', 'additionals'] \n",
        "dev_dataframe_from_file = pd.read_csv('./dev-0/in.tsv', names = test_headers, sep='\\t')\n",
        "test_dataframe_from_file = pd.read_csv('./test-A/in.tsv', names = test_headers, sep='\\t')\n",
        "\n",
        "expected_test_header = ['price']\n",
        "expected_dev_dataframe_from_file = pd.read_csv('./dev-0/expected.tsv', names = expected_test_header, sep='\\t')\n",
        "expected_dev_dataframe_from_file['price'] = expected_dev_dataframe_from_file['price'].astype(float)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnYt2KsaYKAs"
      },
      "source": [
        "train_dataframe = copy.copy(train_dataframe_from_file)\n",
        "dev_dataframe = copy.copy(dev_dataframe_from_file)\n",
        "dev_expected_dataframe = copy.copy(expected_dev_dataframe_from_file)\n",
        "test_dataframe = copy.copy(test_dataframe_from_file)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1EhY-IuYKAu"
      },
      "source": [
        "def preprocesing_datasets(data, is_train_set=False):    \n",
        "    # zamiana str 'zł' na liczby\n",
        "    data.drop(['url', 'ad', \n",
        "                    'empty1', 'empty2', 'empty3', 'empty4', 'empty5', 'empty6',\n",
        "                    'date', 'built_in_year', 'description', 'additionals'], axis=1, inplace=True)\n",
        "    data['rent'] = data['rent'].replace({'zł': ''}, regex=True)\n",
        "    data['rent'] = data['rent'].replace({' ': ''}, regex=True)\n",
        "  \n",
        "    # liczby na float\n",
        "    data['price_per_meter'] = data['price_per_meter'].astype(float)\n",
        "    data['meters'] = data['meters'].astype(str)\n",
        "    data['meters'] = data['meters'] = data['meters'].astype(str) \n",
        "    data['meters'] = data['meters'].replace({' ': ''}, regex=True)\n",
        "    data['meters'] = data['meters'].astype(float)\n",
        "    \n",
        "    mapping_type_of_destination = [(3, 'do zamieszkania'), (2, 'do wykończenia'), (1, 'do remontu'), (0, 'nan')]\n",
        "\n",
        "    data['type_of_destination'] = data['type_of_destination'].replace('do zamieszkania', 3)\n",
        "    data['type_of_destination'] = data['type_of_destination'].replace('do wykończenia', 2)\n",
        "    data['type_of_destination'] = data['type_of_destination'].replace('do remontu', 1)\n",
        "    data['type_of_destination'] = data['type_of_destination'].fillna(0)\n",
        "\n",
        "    data['type_of_destination'] = data['type_of_destination'].astype(int)\n",
        "    data['rent'] = data['rent'].fillna(0)\n",
        "    data['max_floor'] = data['max_floor'].fillna(0)\n",
        "\n",
        "\n",
        "    mapping_type_of_building = [\n",
        "        ('blok', 3), ('szeregowiec', 5), ('kamienica', 4), ('nan', 0), ('apartamentowiec', 7), ('dom wolnostojący', 6),\n",
        "        ('plomba', 1), ('loft', 2)]\n",
        "\n",
        "    data['type_of_building'] = data['type_of_building'].fillna(0)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('plomba', 1)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('loft', 2)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('blok', 3)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('kamienica', 4)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('szeregowiec', 5)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('dom wolnostojący', 6)\n",
        "    data['type_of_building'] = data['type_of_building'].replace('apartamentowiec', 7)\n",
        "\n",
        "\n",
        "    mapping_ownership = [\n",
        "        ('spółdzielcze własnościowe', 3), ('pełna własność', 4), ('nan', 0), ('spółdzielcze wł. z KW', 2),\n",
        "        ('udział', 1)]\n",
        "\n",
        "    data['ownership'] = data['ownership'].replace('pełna własność', 4)\n",
        "    data['ownership'] = data['ownership'].replace('spółdzielcze własnościowe', 3)\n",
        "    data['ownership'] = data['ownership'].replace('spółdzielcze wł. z KW', 2)\n",
        "    data['ownership'] = data['ownership'].replace('udział', 1)\n",
        "    data['ownership'] = data['ownership'].fillna(0)\n",
        "\n",
        "\n",
        "    mapping_heating = [\n",
        "        ('gazowe', 6), ('miejskie', 4), ('nan', 0), ('inne', 1), ('elektryczne', 5), ('kotłownia', 2),\n",
        "        ('piece kaflowe', 3)]\n",
        "\n",
        "    data['heating'] = data['heating'].replace('gazowe', 6)\n",
        "    data['heating'] = data['heating'].replace('elektryczne', 5)\n",
        "    data['heating'] = data['heating'].replace('miejskie', 4)\n",
        "    data['heating'] = data['heating'].replace('piece kaflowe', 3)\n",
        "    data['heating'] = data['heating'].replace('kotłownia', 2)\n",
        "    data['heating'] = data['heating'].replace('inne', 1)\n",
        "    data['heating'] = data['heating'].fillna(0)\n",
        "\n",
        "\n",
        "    mapping_windows_type = [('aluminiowe', 3), ('drewniane', 2), ('plastikowe', 1), ('nan', 0)]\n",
        "\n",
        "    data['windows_type'] = data['windows_type'].replace('aluminiowe', 3)\n",
        "    data['windows_type'] = data['windows_type'].replace('drewniane', 2)\n",
        "    data['windows_type'] = data['windows_type'].replace('plastikowe', 1)\n",
        "    \n",
        "    data['windows_type'] = data['windows_type'].fillna(0)\n",
        "\n",
        "\n",
        "    mapping_type_of_material = [ \n",
        "        ('cegła', 8),('wielka płyta', 1), ('silikat', 6), ('pustak', 5), ('żelbet', 4), ('beton', 3),\n",
        "        ('beton komórkowy', 2), ('inne', 7), ('nan', 0)]\n",
        "\n",
        "    data['type_of_material'] = data['type_of_material'].replace('cegła', 7)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('silikat', 6)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('pustak', 5)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('żelbet', 4)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('beton', 3)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('beton komórkowy', 2)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('inne', 2)\n",
        "    data['type_of_material'] = data['type_of_material'].replace('wielka płyta', 1)\n",
        "    data['type_of_material'] = data['type_of_material'].fillna(0)\n",
        "\n",
        "\n",
        "    mapping_used = [('wtórny', 1), ('pierwotny',  2)]\n",
        "\n",
        "    data['used'] = data['used'].replace('pierwotny', 2)\n",
        "    data['used'] = data['used'].replace('wtórny', 1)\n",
        "    data['floor'] = data['floor'].replace('> 10',  12)\n",
        "    data['floor'] = data['floor'].replace('poddasze', 11)\n",
        "    data['floor'] = data['floor'].replace('suterena', -1)\n",
        "    data['floor'] = data['floor'].replace('parter', 0)\n",
        "    data['floor'] = data['floor'].fillna(-2)\n",
        "\n",
        "    data['number_of_rooms'] = data['number_of_rooms'].replace('więcej niż 10',  11)\n",
        "    data['floor'] = data['floor'].astype(int)\n",
        "    data['rent'] = data['rent'].astype(float)\n",
        "    data['number_of_rooms'] = data['number_of_rooms'].astype(int)\n",
        "    data['used'] = data['used'].astype(int)\n",
        "    data['type_of_material'] = data['type_of_material'].astype(int)\n",
        "    data['windows_type'] = data['windows_type'].astype(int)\n",
        "    data['heating'] = data['heating'].astype(int)\n",
        "    data['ownership'] = data['ownership'].astype(int)\n",
        "    data['type_of_building'] = data['type_of_building'].astype(int)\n",
        "    data['type_of_destination'] = data['type_of_destination'].astype(int) \n",
        "    data['max_floor'] = data['max_floor'].astype(int)\n",
        "    \n",
        "    if is_train_set is True:\n",
        "        data['price'] = data['price'].astype(float)\n",
        "    return data"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5j7NM5dYKAv"
      },
      "source": [
        "# Preprocesing train_dataframe\n",
        "training_dataframe = preprocesing_datasets(train_dataframe, is_train_set=True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUCTT6nUYKAv"
      },
      "source": [
        "# Preprocesing dev_dataframe\n",
        "dev_dataframe = preprocesing_datasets(dev_dataframe)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8KBHapqYKAw"
      },
      "source": [
        "# Preprocesing test_dataframe\n",
        "test_dataframe = preprocesing_datasets(test_dataframe)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yJ0RHDYKAx",
        "outputId": "8b4d5140-4650-4afe-b236-1b01a75bdf9d"
      },
      "source": [
        "t_num_rows = len(train_dataframe)\n",
        "print(F\"Train set liczba wierszy: {t_num_rows}\")\n",
        "\n",
        "d_num_rows = len(dev_dataframe)\n",
        "print(F\"Dev set liczba wierszy: {d_num_rows}\")\n",
        "\n",
        "test_num_rows = len(test_dataframe)\n",
        "print(F\"Test set liczba wierszy: {test_num_rows}\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set liczba wierszy: 2547\n",
            "Dev set liczba wierszy: 462\n",
            "Test set liczba wierszy: 418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znz0IA9qYKAx"
      },
      "source": [
        "input_cols = ['rent','price_per_meter', 'number_of_rooms', 'meters', 'max_floor', 'floor']\n",
        "categorical_cols = ['type_of_destination', 'ownership', 'used', 'type_of_building', 'heating', 'windows_type', 'type_of_material']\n",
        "output_cols = ['price']"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwkdAR0oYKAx"
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "        \n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_6vxcm_YKAy"
      },
      "source": [
        "def test_dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "        \n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    return inputs_array"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brwD-ZoYYKAz"
      },
      "source": [
        "# Create train input and traget arrays \n",
        "train_inputs_array, train_targets_array = dataframe_to_arrays(train_dataframe)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax281nrYYKA0"
      },
      "source": [
        "# dev set\n",
        "dev_dataframe['price'] = dev_expected_dataframe['price'] \n",
        "dev_inputs_array, dev_targets_array = dataframe_to_arrays(dev_dataframe)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXqeMt_uYKA0"
      },
      "source": [
        "def check_len(input_array, target_array):\n",
        "    current_len = len(input_array[0])\n",
        "    for num, i in enumerate(input_array):\n",
        "        if len(i) != current_len:\n",
        "            print('break INPUT:', num)\n",
        "            break\n",
        "            \n",
        "    current_len = len(target_array[0])\n",
        "    for num, i in enumerate(target_array):\n",
        "        if len(i) != current_len:\n",
        "            print('break TARGET: ', num)\n",
        "            break\n",
        "    \n",
        "    if len(input_array) != len(target_array):\n",
        "        print(f\"{len(input_array)} \\!\\= {len(target_array)}\")\n",
        "        \n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRxzbhFhYKA0"
      },
      "source": [
        "# test set input array \n",
        "test_inputs_array = test_dataframe_to_arrays(test_dataframe)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn5udbZGYKA1",
        "outputId": "a46fd058-db2a-409d-b167-bcf2a171b1e2"
      },
      "source": [
        "# Convert to float\n",
        "# train set\n",
        "t_inputs = torch.from_numpy(train_inputs_array).float()\n",
        "t_targets = torch.from_numpy(train_targets_array).float()\n",
        "print(\"TRAIN:\")\n",
        "print(t_inputs[:2])\n",
        "print(t_targets[:2])\n",
        "\n",
        "# dev set\n",
        "d_inputs = torch.from_numpy(dev_inputs_array).float()\n",
        "d_targets = torch.from_numpy(dev_targets_array).float()\n",
        "print(\"DEV:\")\n",
        "print(d_inputs[:2])\n",
        "print(d_targets[:2])\n",
        "\n",
        "# test set\n",
        "test_inputs = torch.from_numpy(test_inputs_array).float()\n",
        "test_targets = torch.from_numpy(np.zeros((len(test_inputs),1)))\n",
        "print(\"TEST:\")\n",
        "print(test_inputs[:2])\n",
        "print(test_targets[:2])\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN:\n",
            "tensor([[3.9000e+02, 7.1130e+03, 2.0000e+00, 4.3440e+01, 4.0000e+00, 1.0000e+00],\n",
            "        [0.0000e+00, 7.3920e+03, 2.0000e+00, 4.2600e+01, 2.0000e+00, 1.0000e+00]])\n",
            "tensor([[309000.],\n",
            "        [314900.]])\n",
            "DEV:\n",
            "tensor([[2.5000e+02, 6.3110e+03, 3.0000e+00, 5.9100e+01, 4.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 7.8680e+03, 2.0000e+00, 3.8000e+01, 1.2000e+01, 4.0000e+00]])\n",
            "tensor([[373000.],\n",
            "        [299000.]])\n",
            "TEST:\n",
            "tensor([[0.0000e+00, 6.9380e+03, 3.0000e+00, 6.1990e+01, 7.0000e+00, 2.0000e+00],\n",
            "        [0.0000e+00, 6.0780e+03, 4.0000e+00, 6.4000e+01, 4.0000e+00, 0.0000e+00]])\n",
            "tensor([[0.],\n",
            "        [0.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbDl4_B_YKA1"
      },
      "source": [
        "# Create Train TensorDataset\n",
        "train_dataset = TensorDataset(t_inputs, t_targets)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AlTAhbFYKA1"
      },
      "source": [
        "# Create Dev TensorDataset\n",
        "dev_dataset = TensorDataset(d_inputs, d_targets)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZrcXHEUYKA1"
      },
      "source": [
        "# Create Test TensorDataset\n",
        "\n",
        "test_dataset = TensorDataset(test_inputs, test_targets)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avCWabDPYKA2"
      },
      "source": [
        "# Size of datasets\n",
        "t_val_size = t_num_rows\n",
        "d_val_size = d_num_rows\n",
        "\n",
        "\n",
        "train_ds = copy.copy(train_dataset)\n",
        "\n",
        "val_ds = copy.copy(dev_dataset)\n",
        "\n",
        "test_ds = copy.copy(test_dataset)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xjJB4C-YKA2"
      },
      "source": [
        "batch_size = 100\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)\n",
        "test_loader = DataLoader(test_ds, batch_size)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SlG4YVRYKA2"
      },
      "source": [
        "# Step 3: Create a Linear Regression Model"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBdnGxALYKA3"
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImZ1QGGqYKA3"
      },
      "source": [
        "class PriceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)  \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr0C7J6OYKA3"
      },
      "source": [
        "model = PriceModel()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8k7PPs6YKA4"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrTh8L-aYKA4",
        "outputId": "fc3305a1-4d53-42c7-f3c6-6baa485a35bc"
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 421839.34375}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GckF3ZrEYKA5",
        "outputId": "15a0ec0d-c641-40a7-d9a4-e6d4d5fef216"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-2\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 196420.6250\n",
            "Epoch [40], val_loss: 188458.5938\n",
            "Epoch [60], val_loss: 173731.3281\n",
            "Epoch [80], val_loss: 151665.8906\n",
            "Epoch [100], val_loss: 214904.7188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AsJYVnfYKA6",
        "outputId": "7bbf3a9a-75db-4906-91e0-2452a58993ef"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-3\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 134672.7500\n",
            "Epoch [40], val_loss: 135195.6250\n",
            "Epoch [60], val_loss: 136107.3281\n",
            "Epoch [80], val_loss: 133085.2969\n",
            "Epoch [100], val_loss: 135847.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02HFqfQJYKA6",
        "outputId": "b45449ca-188d-425a-e4a3-cc3a5f2442e4"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-4\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 133568.2188\n",
            "Epoch [40], val_loss: 133462.8281\n",
            "Epoch [60], val_loss: 133212.8906\n",
            "Epoch [80], val_loss: 133837.1719\n",
            "Epoch [100], val_loss: 133276.5938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41B5KhmUYKA7",
        "outputId": "abc6dec1-e9bd-4dfa-dc7a-2c7bf52ad7df"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-5\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 133502.0938\n",
            "Epoch [40], val_loss: 133486.7969\n",
            "Epoch [60], val_loss: 133458.5938\n",
            "Epoch [80], val_loss: 133489.4375\n",
            "Epoch [100], val_loss: 133473.2812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxzwGhEDYKA7",
        "outputId": "03c6b7bd-e526-43a6-dddf-8dd41fffbe18"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-6\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 133471.0469\n",
            "Epoch [40], val_loss: 133480.4062\n",
            "Epoch [60], val_loss: 133475.5938\n",
            "Epoch [80], val_loss: 133475.8438\n",
            "Epoch [100], val_loss: 133484.0156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR7sslK_YKA8",
        "outputId": "f6cc45c2-60a3-430a-93c0-c70a95023790"
      },
      "source": [
        "epochs = 100\n",
        "lr = 1e-7\n",
        "history6 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 133483.7188\n",
            "Epoch [40], val_loss: 133483.5938\n",
            "Epoch [60], val_loss: 133483.4688\n",
            "Epoch [80], val_loss: 133483.2031\n",
            "Epoch [100], val_loss: 133483.0156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJnFpUSIYKA8"
      },
      "source": [
        "val_loss = [result] + history1 + history2 + history3 + history4 + history5+ history6\n",
        "val_loss_list = [vl['val_loss'] for vl in val_loss]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85WBFraPYKA8"
      },
      "source": [
        "val_loss = [result] + history1 + history2 + history3 + history4 + history5\n",
        "val_loss_list = [vl['val_loss'] for vl in val_loss]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRSHfH0QYKA8"
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QojVD5rsYKA8",
        "outputId": "505fbce7-1dff-47f3-d9fe-c5312f7b8a83"
      },
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([2.5000e+02, 6.3110e+03, 3.0000e+00, 5.9100e+01, 4.0000e+00, 2.0000e+00])\n",
            "Target: tensor([373000.])\n",
            "Prediction: tensor([350319.9688])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMtqLI_EYKA9",
        "outputId": "a4b4995a-e5f6-4d34-843a-af7c1e4c4cad"
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([0.0000e+00, 7.8650e+03, 2.0000e+00, 3.8500e+01, 3.0000e+00, 1.0000e+00])\n",
            "Target: tensor([302800.])\n",
            "Prediction: tensor([362455.4062])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7gq2sNNYKA9",
        "outputId": "5c3af97c-fd8d-4725-c6c5-e3c7cf6a29f4"
      },
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([0.0000e+00, 5.5200e+03, 3.0000e+00, 6.9750e+01, 5.0000e+00, 5.0000e+00])\n",
            "Target: tensor([385000.])\n",
            "Prediction: tensor([344435.8125])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fdR9o1wYKA9"
      },
      "source": [
        "# Test-A\n",
        "\n",
        "def predict_test_single(input, model):\n",
        "    \n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)\n",
        "    prediction = predictions[0].detach()\n",
        "    \n",
        "    #print(\"Input:\", input)\n",
        "    #print(\"Out:\", prediction)\n",
        "    return prediction.numpy()[0]\n",
        "    \n",
        "predictions=[]\n",
        "for num, (xb, yb) in enumerate(test_ds):\n",
        "    predictions.append(predict_test_single(xb, model))\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFNxXSLYKA9"
      },
      "source": [
        "dev_predictions=[]\n",
        "for num, (xb, yb) in enumerate(val_ds):\n",
        "    dev_predictions.append(predict_test_single(xb, model))"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voS-ok4XYKA-"
      },
      "source": [
        "#generowanie test-A/out.tsv \n",
        "import csv\n",
        "with open('./test-A/out.tsv', 'wt') as f:\n",
        "    writer = csv.writer(f, delimiter='\\t')\n",
        "    for row in predictions:\n",
        "        writer.writerow([row])"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsD9l86hYKA-"
      },
      "source": [
        "#generowanie dev-0/out.tsv \n",
        "\n",
        "with open('./dev-0/out.tsv', 'w') as f:\n",
        "    writer = csv.writer(f, delimiter='\\t')\n",
        "    for row in list(dev_predictions):\n",
        "        writer.writerow([row])"
      ],
      "execution_count": 113,
      "outputs": []
    }
  ]
}